{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+NZ0v3MSgmAeJOpnU5zUo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leomercanti/SP500_Predictors_LSTM_Linear_Regression/blob/main/SP500_Predictors_LSTM_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **S&P 500 Prediction Project - Linear Regression and LSTM Models**\n",
        "\n"
      ],
      "metadata": {
        "id": "eRiqGnEKCdv2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Import Libraries:**\n",
        "\n",
        "Import the necessary libraries for data fetching, preprocessing, modeling, and visualization."
      ],
      "metadata": {
        "id": "szbUPoUjDzSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input"
      ],
      "metadata": {
        "id": "UpBG4VerCeCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install keras-tuner\n",
        "!pip install keras-tuner"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pX9Wi1CiGd-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_tuner import HyperModel, RandomSearch"
      ],
      "metadata": {
        "id": "U03wlMo_GjAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 1: Fetch Historical Data**\n",
        "\n",
        "Use yfinance to download historical data for the S&P 500 and extract yearly closing prices."
      ],
      "metadata": {
        "id": "RIAcBw3nDvQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download historical S&P 500 data\n",
        "sp500 = yf.Ticker('^GSPC')\n",
        "data = sp500.history(period='max')"
      ],
      "metadata": {
        "id": "6aKIaj3XCuTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract yearly closing prices\n",
        "yearly_data = data['Close'].resample('Y').last().dropna()"
      ],
      "metadata": {
        "id": "HgXOY6EyCzxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 2: Visualize Historical Data**\n",
        "\n",
        "Plot the yearly closing prices to understand the trend visually."
      ],
      "metadata": {
        "id": "uM6qghu9EBqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the yearly closing data\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(yearly_data, label='S&P 500 Yearly Closing Price', color='blue')\n",
        "plt.title('S&P 500 Yearly Closing Price (Historical Data)')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Closing Price')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g2K8l2BzC7NT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 3: Prepare Data for Modeling**\n",
        "\n",
        "Compute yearly returns and normalize the data to fit the models."
      ],
      "metadata": {
        "id": "mCn44e15EIRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute yearly returns\n",
        "yearly_data = pd.DataFrame(yearly_data)\n",
        "yearly_data['Returns'] = yearly_data['Close'].pct_change()"
      ],
      "metadata": {
        "id": "rQlMOf8vDBG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(yearly_data[['Close', 'Returns']].dropna())"
      ],
      "metadata": {
        "id": "KnQiDuCDDIV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create features and labels for modeling\n",
        "X = scaled_data[:-1]\n",
        "y = scaled_data[1:, 0]  # Predicting next yearâ€™s closing price"
      ],
      "metadata": {
        "id": "M5pIscqMDM-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 4: Split Data into Train and Test Sets**\n",
        "\n",
        "Divide the dataset into training and testing subsets."
      ],
      "metadata": {
        "id": "YQuuO6hbEWkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
      ],
      "metadata": {
        "id": "JsKzlJoEDQ9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 5: Train Linear Regression Model**\n",
        "\n",
        "Fit a linear regression model on the training data."
      ],
      "metadata": {
        "id": "auOpCgUyEn_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "jV5FTrgJDVOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 6: Evaluate Linear Regression Model**\n",
        "\n",
        "Make predictions using the test set and calculate MSE."
      ],
      "metadata": {
        "id": "-SUtgM6iExFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lr = lr_model.predict(X_test)\n",
        "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
        "print(f\"Linear Regression MSE: {mse_lr}\")"
      ],
      "metadata": {
        "id": "4XylXfT2DX6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 7: Prepare Data for LSTM**\n",
        "\n",
        "Reshape the data for the LSTM model, which requires 3D input."
      ],
      "metadata": {
        "id": "3At78CWYE2_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape data for LSTM (input should be 3D for LSTM)\n",
        "X_train_lstm = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))"
      ],
      "metadata": {
        "id": "l3LAHFFYDaMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 8: Build and Train LSTM Model**\n",
        "\n",
        "Construct and train the LSTM model."
      ],
      "metadata": {
        "id": "eA_oryI1E9aP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
        "model.add(LSTM(50, return_sequences=True))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(1))"
      ],
      "metadata": {
        "id": "R_nvfewEDcq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and fit the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(X_train_lstm, y_train, epochs=50, batch_size=16, verbose=1)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-u-mWnj1De_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 9: Evaluate LSTM Model**\n",
        "\n",
        "Calculate MSE for the LSTM predictions."
      ],
      "metadata": {
        "id": "OkRuFuVwFEL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lstm = model.predict(X_test_lstm)"
      ],
      "metadata": {
        "id": "B9NGamb2DhN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the array for inverse transformation\n",
        "y_test_lstm = scaler.inverse_transform(np.column_stack((X_test[:, 0], np.zeros(X_test.shape[0]))))[:, 0]"
      ],
      "metadata": {
        "id": "RTP-awDyDjc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse transform the predictions with the appropriate shape\n",
        "y_pred_lstm_inverse = scaler.inverse_transform(np.column_stack((y_pred_lstm.flatten(), np.zeros(y_pred_lstm.shape[0]))))[:, 0]"
      ],
      "metadata": {
        "id": "A6FbVYb3IeF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MSE\n",
        "mse_lstm = mean_squared_error(y_test_lstm, y_pred_lstm_inverse)\n",
        "print(f\"LSTM MSE: {mse_lstm}\")"
      ],
      "metadata": {
        "id": "GOXb9JOFIgSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 10: Visualize Predictions**"
      ],
      "metadata": {
        "id": "3jbhbh6ZFJ6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(y_test, label='Actual', color='blue')\n",
        "plt.plot(y_pred_lr, label='LR Predicted', color='red', linestyle='dashed')\n",
        "plt.plot(y_pred_lstm, label='LSTM Predicted', color='orange', linestyle='dotted')\n",
        "plt.title('Actual vs Predicted S&P 500 Yearly Closing Prices')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Closing Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zw0SOht5DlcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 11: Hyperparameter Tuning for LSTM**\n",
        "\n",
        "Use Keras Tuner to optimize hyperparameters for the LSTM model."
      ],
      "metadata": {
        "id": "BEHxPsCTFQS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMHyperModel(HyperModel):\n",
        "    def build(self, hp):\n",
        "        model = Sequential()\n",
        "        model.add(Input(shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
        "        model.add(LSTM(hp.Int('units', min_value=32, max_value=128, step=32), return_sequences=True))\n",
        "        model.add(LSTM(hp.Int('units', min_value=32, max_value=128, step=32)))\n",
        "        model.add(Dense(1))\n",
        "        model.compile(optimizer='adam', loss='mse')\n",
        "        return model\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    LSTMHyperModel(),\n",
        "    objective='val_loss',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=1,\n",
        "    directory='lstm_tuning',\n",
        "    project_name='sp500_lstm_tuning'\n",
        ")\n",
        "\n",
        "tuner.search(X_train_lstm, y_train, epochs=50, batch_size=16, validation_data=(X_test_lstm, y_test))\n",
        "best_model = tuner.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "id": "9_AgKLzzDnUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 12: Combine Predictions from Different Models**\n",
        "\n",
        "Average predictions from the Linear Regression and LSTM models."
      ],
      "metadata": {
        "id": "3id-PZnNFXa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_predictions = (y_pred_lr + y_pred_lstm.flatten()) / 2\n",
        "mse_combined = mean_squared_error(y_test, combined_predictions)\n",
        "print(f\"Combined Model MSE: {mse_combined}\")"
      ],
      "metadata": {
        "id": "TJJTcV0IDpwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 13: Visualize Combined Predictions**\n",
        "\n",
        "Plot actual vs. predicted values from both models and the combined predictions."
      ],
      "metadata": {
        "id": "qmfRZ-AvFdie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(y_test, label='Actual', color='blue')\n",
        "plt.plot(y_pred_lr, label='LR Predicted', color='red', linestyle='dashed')\n",
        "plt.plot(y_pred_lstm, label='LSTM Predicted', color='orange', linestyle='dotted')\n",
        "plt.plot(combined_predictions, label='Combined Predicted', color='green', linestyle='dashdot')\n",
        "plt.title('Actual vs Combined Predicted S&P 500 Yearly Closing Prices')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Closing Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BUIkF2bjDrkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 14: Generate Future Predictions**\n",
        "\n",
        "Make predictions for the next ten years and print the predicted values."
      ],
      "metadata": {
        "id": "-jTnu6xAFozT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "future_years = 10  # Number of years to predict\n",
        "last_data_point = scaled_data[-1].reshape(1, -1)  # Start with the last known data point\n",
        "\n",
        "for i in range(future_years):\n",
        "    future_pred = lr_model.predict(last_data_point)  # Make prediction\n",
        "\n",
        "    # Inverse transform the prediction\n",
        "    predicted_value = scaler.inverse_transform(np.array([[future_pred[0], 0]]))[0][0]\n",
        "    print(f\"Predicted closing price for year {i+1}: {predicted_value}\")\n",
        "\n",
        "    # Update last_data_point with the new prediction for the next iteration\n",
        "    last_data_point[0, 0] = future_pred[0]  # Update the relevant feature with the prediction"
      ],
      "metadata": {
        "id": "Kpq0t5LkDtcC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}